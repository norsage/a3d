defaults:
  - _self_
  - model: default_t5.yaml
  - trainer: ddp.yaml

root_dir: ${oc.env:PROJECT_ROOT}
task_name: a3d
experiment_name: tiny_t5
output_dir: ${hydra:runtime.output_dir}
logdir: ${root_dir}/logs/

seed: 0

datamodule:
  _target_: a3d.datamodule.lit.Seq2SeqDataModule
  datadir: data/processed/
  train_csv: sabdab_train.csv
  validation_csv: sabdab_val.csv
  batch_size: 32
  num_workers: 0

trainer:
  check_val_every_n_epoch: null
  val_check_interval: 256
  max_epochs: -1
  max_steps: 12800

callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: val_loss
    mode: "min"
    dirpath: ${output_dir}/checkpoints
    filename: "epoch_{epoch:03d}"
    save_last: True
    save_top_k: 1 # save k best models (determined by above metric)
    auto_insert_metric_name: False

  generate:
    _target_: a3d.utils.callbacks.GenerateSequences
    n_sequences: 5
    n_samples: 100

logger:
  aim:
    _target_: aim.pytorch_lightning.AimLogger
    repo: ${logdir}/${task_name}
    experiment: ${experiment_name}

hydra:
  run:
    dir: ${logdir}/${task_name}/runs/${now:%Y-%m-%d}/${now:%H:%M:%S}

  sweep:
    dir: ${logdir}/${task_name}/multiruns/${now:%Y-%m-%d}/${now:%H:%M:%S}/
    subdir: ${hydra.job.override_dirname}
